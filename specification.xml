<?xml version="1.0" encoding="UTF-8" ?>

<!--
Normally we'd collect information about your projects using an online form,
but the CS web-site is being retired and SAFE isn't up to the task yet.  As
an interim solution the idea is that

- you complete this XML file, replacing the template content but retaining
  the structure, and submit it via SAFE,
  then
- later, and hopefully (semi-)automatically, we'll import it into SAFE for
  you in order to drive the assessment process.

This submission represents a draft specification.  Completion of the content
below is an exercise in formative assessment only: it is a way to a) explore
the viability of initial ideas, and refine these where need be, and b) allow
provision of feedback.  We therefore want a clear, concise specification of
no more than one page of A4.

If in doubt about the content of the longer sections, make sure you read the
unit handbook at


-->

 <project>

<!--
In this section, we want

1. your CS user name
   (e.g., "jl8971"),
2. your project title (even if you change this later),
3. the full name of                your Supervisor within  CS,
   (e.g., "Daniel Page"),
4. whether said Supervisor is  confirmed or tentative,
5. the full name (and affiliation) any  Advisor(s) outside CS
   (e.g., an industrial collaborator such as "Fred Bloggs, IBM"),
6. whether said Advisor(s) are confirmed or tentative,
   and
7. whether your project is of type enterprise or research (which implies you
   are also registered on the associated "sister unit").
-->

  <admin>
               <username> bf15007               </username>
                  <title> Image Quality Assessment for Manta Ray Identification </title>

             <supervisor> Tilo Burghardt        </supervisor>
   <confirmed_supervisor> yes                   </confirmed_supervisor>

                <advisor> ...                   </advisor>
      <confirmed_advisor> n/a                   </confirmed_advisor>

                   <type> research </type>
 </admin>

<!--
In this section we want a high-level description of the project; the content
might include a description of what the central problem is, and any previous
or related work done to solve it.
-->

  <description>
  Currently there exist machine learning systems for the identification of
  individual manta rays in images. These systems are trained on large data sets
  containing thousands of such images. However, the quality of samples in the
  data sets is inconsistent, due to the highly variable underwater conditions
  these photos are taken in. Factors such as lighting, fog, resolution,
  the position of the manta ray and the quality of their unique ventral surface
  patterns can affect the quality of each image, which in turn can have a
  negative impact on the training process.
  The issue being investigated for this project is therefore one of how we can
  use machines to separate quality cases in such a way that poor quality images
  are rejected from training. In the case of this project, the performance of
  deep learning methods for this task will be assessed, a neural network
  being trained to predict the quality of each image in a data set. This will
  require the creation of a human-annotated data set according to subjective
  measures of quality.
  This will lead into investigating how automatically eliminating poor quality
  samples from a data set can have any positive impact on the performance of a
  classification system, and where machines do and do not succeed in measuring
  the quality of an image.
 </description>

<!--
In this section we want a low(er)-level outline of exactly what you will to
do within the project.  The easiest way to structure this is as a concise,
focused set of bullet points outlining a) the high-level objective(s), and
b) concrete, step-by-step aims that will move you towards this.
-->

  <obj>
  -Annotate manta ray dataset
  --Identify criteria for image quality
  --Develop small python script for quick labelling of each image according to criteria
  -Development of baseline system
  --Training script for a simple neural network
  --Comparison of model's assessment with own subjective assessment of quality
  -Development of final model
  --Analyse failure cases and making appropriate changes to baseline model
  --Experiment with different dataset configurations, size, quality criteria, etc
  -Comparison with classification systems
  --Run classification on reduced dataset containing images deemed to be of high quality by the model, and compare accuracy to classification with an unchanged dataset
  </obj>

<!--
In this section we want a draft plan for execution of the outlined aims and
objectives.  This often focusses on time scales, but, crucially, you should
carefully read

http://www.cs.bris.ac.uk/Teaching/hse.pdf

and, where appropriate, include

a) a heath and safety risk assessment, and
b) a statement of any potential ethics implications

plus suitable contingency planning for the issues identified.
-->

  <plan>
  Week 13 - Week 14:
  -Manually annotate data set according to perceived quality
  -First training runs of a baseline system
  Week 15 - Week 18:
  -Further optimisation and testing of model
  -Analysis of failure cases
  -Improvements to model
  Week 19:
  -Poster fair: presentation of results so far
  Week 20 - Week 21:
  -Acting on feedback from poster fair
  -Final model produced
  -Possible experimentation with larger datasets
  EV1 - EV3:
  -Write-up of bulk of evaluation
  Week 22 - Week 24:
  -Final tests and results
  -Comparison with existing classification systems
  -Completion and submission of final dissertation
 </plan>

</project>
